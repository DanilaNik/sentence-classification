{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "0b29cdce",
   "metadata": {
    "cellId": "9uqjbhv9ph7fpsegkt1s04"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>1category</th>\n",
       "      <th>2category</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4754</td>\n",
       "      <td>При этом всегда получал качественные услуги.</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4417</td>\n",
       "      <td>Не вижу, за что хотя бы 2 поставить, сервис на 1!</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3629</td>\n",
       "      <td>Вот так \"Мой любимый\" банк МКБ меня обманул.</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11640</td>\n",
       "      <td>Отвратительное отношение к клиентам.</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5571</td>\n",
       "      <td>Всегда в любое время дня и ночи помогут, ответ...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19356</th>\n",
       "      <td>8004</td>\n",
       "      <td>Никогда и ни в коем случае не открывайте счет ...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19357</th>\n",
       "      <td>18182</td>\n",
       "      <td>ТИ откровенно забили на качество и развивают с...</td>\n",
       "      <td>Quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19358</th>\n",
       "      <td>744</td>\n",
       "      <td>Я считаю, это прорыв и лидерство финансовых ус...</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19359</th>\n",
       "      <td>6220</td>\n",
       "      <td>Писал мужчина очень доходчиво, не финансовым я...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19360</th>\n",
       "      <td>8433</td>\n",
       "      <td>Данная ситуация меня сильно выбила из колеи, и...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19361 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  ... sentiment\n",
       "0            4754  ...         +\n",
       "1            4417  ...         −\n",
       "2            3629  ...         −\n",
       "3           11640  ...         −\n",
       "4            5571  ...         +\n",
       "...           ...  ...       ...\n",
       "19356        8004  ...         −\n",
       "19357       18182  ...         −\n",
       "19358         744  ...         +\n",
       "19359        6220  ...         +\n",
       "19360        8433  ...         −\n",
       "\n",
       "[19361 rows x 5 columns]"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "data = pd.read_csv('/home/jupyter/mnt/s3/main-data/dataset/train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "03c73b12",
   "metadata": {
    "cellId": "9zre2nsbkr9zvvfjotlekd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sentence', '1category', '2category', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "ce4ad41b",
   "metadata": {
    "cellId": "fncv581tv8foaonb6xubsk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>При этом всегда получал качественные услуги.</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Не вижу, за что хотя бы 2 поставить, сервис на 1!</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Вот так \"Мой любимый\" банк МКБ меня обманул.</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Отвратительное отношение к клиентам.</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Всегда в любое время дня и ночи помогут, ответ...</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19356</th>\n",
       "      <td>Никогда и ни в коем случае не открывайте счет ...</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19357</th>\n",
       "      <td>ТИ откровенно забили на качество и развивают с...</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19358</th>\n",
       "      <td>Я считаю, это прорыв и лидерство финансовых ус...</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19359</th>\n",
       "      <td>Писал мужчина очень доходчиво, не финансовым я...</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19360</th>\n",
       "      <td>Данная ситуация меня сильно выбила из колеи, и...</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19361 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence sentiment\n",
       "0           При этом всегда получал качественные услуги.         +\n",
       "1      Не вижу, за что хотя бы 2 поставить, сервис на 1!         −\n",
       "2           Вот так \"Мой любимый\" банк МКБ меня обманул.         −\n",
       "3                   Отвратительное отношение к клиентам.         −\n",
       "4      Всегда в любое время дня и ночи помогут, ответ...         +\n",
       "...                                                  ...       ...\n",
       "19356  Никогда и ни в коем случае не открывайте счет ...         −\n",
       "19357  ТИ откровенно забили на качество и развивают с...         −\n",
       "19358  Я считаю, это прорыв и лидерство финансовых ус...         +\n",
       "19359  Писал мужчина очень доходчиво, не финансовым я...         +\n",
       "19360  Данная ситуация меня сильно выбила из колеи, и...         −\n",
       "\n",
       "[19361 rows x 2 columns]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "data.drop(columns={'Unnamed: 0', '1category', '2category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "4b238e60",
   "metadata": {
    "cellId": "v0h7iknikv9wla2c188ojs"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sentences = data['sentence'].values\n",
    "y = data['sentiment'].values\n",
    "y = np.where(y=='−', 0, np.where(y=='+', 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "6ad9e4f6",
   "metadata": {
    "cellId": "pkp3zt2vwsg8iorml7477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 16)           80000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 153       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 30        \n",
      "=================================================================\n",
      "Total params: 80,183\n",
      "Trainable params: 80,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 0.9899 - accuracy: 0.5242 - val_loss: 0.9282 - val_accuracy: 0.5261\n",
      "Epoch 2/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.8197 - accuracy: 0.6701 - val_loss: 0.7025 - val_accuracy: 0.7547\n",
      "Epoch 3/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.6352 - accuracy: 0.7631 - val_loss: 0.5900 - val_accuracy: 0.7721\n",
      "Epoch 4/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.5452 - accuracy: 0.7833 - val_loss: 0.5388 - val_accuracy: 0.7831\n",
      "Epoch 5/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.8082 - val_loss: 0.4930 - val_accuracy: 0.8044\n",
      "Epoch 6/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.4457 - accuracy: 0.8303 - val_loss: 0.4759 - val_accuracy: 0.8205\n",
      "Epoch 7/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.4134 - accuracy: 0.8440 - val_loss: 0.4418 - val_accuracy: 0.8438\n",
      "Epoch 8/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3827 - accuracy: 0.8590 - val_loss: 0.4377 - val_accuracy: 0.8373\n",
      "Epoch 9/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3588 - accuracy: 0.8677 - val_loss: 0.4196 - val_accuracy: 0.8528\n",
      "Epoch 10/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3366 - accuracy: 0.8776 - val_loss: 0.4087 - val_accuracy: 0.8573\n",
      "Epoch 11/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3194 - accuracy: 0.8835 - val_loss: 0.3998 - val_accuracy: 0.8580\n",
      "Epoch 12/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3030 - accuracy: 0.8908 - val_loss: 0.4027 - val_accuracy: 0.8573\n",
      "Epoch 13/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2877 - accuracy: 0.8953 - val_loss: 0.3935 - val_accuracy: 0.8644\n",
      "Epoch 14/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2756 - accuracy: 0.9014 - val_loss: 0.3937 - val_accuracy: 0.8657\n",
      "Epoch 15/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.9026 - val_loss: 0.3935 - val_accuracy: 0.8677\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39773622155189514, 0.8649625778198242]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_size = int(len(sentences) * 0.8)\n",
    "train_sentences = sentences[:train_size]\n",
    "train_y = y[:train_size]\n",
    "test_sentences = sentences[train_size:]\n",
    "test_y = y[train_size:]\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=100, padding='post', truncating='post')\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(5000, 16, input_length=100),\n",
    "#     tf.keras.layers.Bidirectional(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(9, activation='relu'),\n",
    "#     tf.keras.layers.Dense(18, activation='relu'),\n",
    "\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "model.fit(\n",
    "    train_padded,\n",
    "    train_y,\n",
    "    epochs=15,\n",
    "    validation_split=0.1\n",
    ")\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=100, padding='post', truncating='post')\n",
    "model.evaluate(test_padded, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "3c18caab",
   "metadata": {
    "cellId": "n0mqg8z0toh0gw7wmye2n"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model.save('/home/jupyter/mnt/s3/main-data/models/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "e5d3c197",
   "metadata": {
    "cellId": "3it729f6crdwpybn16t8al"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 16)           80000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 153       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 30        \n",
      "=================================================================\n",
      "Total params: 80,183\n",
      "Trainable params: 80,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 0.9763 - accuracy: 0.5256 - val_loss: 0.9058 - val_accuracy: 0.5707\n",
      "Epoch 2/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.7768 - accuracy: 0.7098 - val_loss: 0.6550 - val_accuracy: 0.7579\n",
      "Epoch 3/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.5902 - accuracy: 0.7716 - val_loss: 0.5539 - val_accuracy: 0.7792\n",
      "Epoch 4/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.5016 - accuracy: 0.8044 - val_loss: 0.4964 - val_accuracy: 0.8076\n",
      "Epoch 5/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.4407 - accuracy: 0.8354 - val_loss: 0.4546 - val_accuracy: 0.8334\n",
      "Epoch 6/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3962 - accuracy: 0.8531 - val_loss: 0.4280 - val_accuracy: 0.8380\n",
      "Epoch 7/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3573 - accuracy: 0.8691 - val_loss: 0.4083 - val_accuracy: 0.8464\n",
      "Epoch 8/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3298 - accuracy: 0.8775 - val_loss: 0.3959 - val_accuracy: 0.8612\n",
      "Epoch 9/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3035 - accuracy: 0.8886 - val_loss: 0.3927 - val_accuracy: 0.8599\n",
      "Epoch 10/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2838 - accuracy: 0.8965 - val_loss: 0.3925 - val_accuracy: 0.8625\n",
      "Epoch 11/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2672 - accuracy: 0.9023 - val_loss: 0.3941 - val_accuracy: 0.8599\n",
      "Epoch 12/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2533 - accuracy: 0.9071 - val_loss: 0.3907 - val_accuracy: 0.8683\n",
      "Epoch 13/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.9086 - val_loss: 0.3963 - val_accuracy: 0.8683\n",
      "Epoch 14/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2310 - accuracy: 0.9118 - val_loss: 0.4050 - val_accuracy: 0.8638\n",
      "Epoch 15/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2224 - accuracy: 0.9128 - val_loss: 0.4021 - val_accuracy: 0.8722\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41964489221572876, 0.8665117621421814]"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_size = int(len(sentences) * 0.8)\n",
    "train_sentences = sentences[:train_size]\n",
    "train_y = y[:train_size]\n",
    "test_sentences = sentences[train_size:]\n",
    "test_y = y[train_size:]\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=100, padding='post', truncating='post')\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(5000, 16, input_length=100),\n",
    "#     tf.keras.layers.Bidirectional(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(9, activation='tanh'),\n",
    "#     tf.keras.layers.Dense(18, activation='relu'),\n",
    "\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(3, activation='sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "model.fit(\n",
    "    train_padded,\n",
    "    train_y,\n",
    "    epochs=15,\n",
    "    validation_split=0.1\n",
    ")\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=100, padding='post', truncating='post')\n",
    "model.evaluate(test_padded, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "bf6f448e",
   "metadata": {
    "cellId": "r0ndf3xc9a934knn80owu"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model.save('/home/jupyter/mnt/s3/main-data/models/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "20ef6858",
   "metadata": {
    "cellId": "h5e17uhf18er8pefuahtz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 100, 16)           80000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_20  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 9)                 153       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 30        \n",
      "=================================================================\n",
      "Total params: 80,183\n",
      "Trainable params: 80,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 1.0780 - accuracy: 0.4881 - val_loss: 0.9684 - val_accuracy: 0.5261\n",
      "Epoch 2/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.9331 - accuracy: 0.5510 - val_loss: 0.8622 - val_accuracy: 0.5978\n",
      "Epoch 3/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.7278 - accuracy: 0.7300 - val_loss: 0.5947 - val_accuracy: 0.7624\n",
      "Epoch 4/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.5484 - accuracy: 0.7801 - val_loss: 0.5474 - val_accuracy: 0.7702\n",
      "Epoch 5/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.8046 - val_loss: 0.4898 - val_accuracy: 0.8050\n",
      "Epoch 6/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.4401 - accuracy: 0.8300 - val_loss: 0.4650 - val_accuracy: 0.8154\n",
      "Epoch 7/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.4081 - accuracy: 0.8491 - val_loss: 0.4732 - val_accuracy: 0.8179\n",
      "Epoch 8/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3805 - accuracy: 0.8592 - val_loss: 0.4430 - val_accuracy: 0.8399\n",
      "Epoch 9/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3562 - accuracy: 0.8717 - val_loss: 0.4375 - val_accuracy: 0.8464\n",
      "Epoch 10/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8754 - val_loss: 0.4380 - val_accuracy: 0.8528\n",
      "Epoch 11/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3205 - accuracy: 0.8839 - val_loss: 0.4838 - val_accuracy: 0.8399\n",
      "Epoch 12/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3061 - accuracy: 0.8867 - val_loss: 0.4427 - val_accuracy: 0.8593\n",
      "Epoch 13/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2953 - accuracy: 0.8917 - val_loss: 0.4578 - val_accuracy: 0.8522\n",
      "Epoch 14/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2803 - accuracy: 0.8963 - val_loss: 0.4343 - val_accuracy: 0.8612\n",
      "Epoch 15/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.8983 - val_loss: 0.4342 - val_accuracy: 0.8638\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4364631175994873, 0.852827250957489]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_size = int(len(sentences) * 0.8)\n",
    "train_sentences = sentences[:train_size]\n",
    "train_y = y[:train_size]\n",
    "test_sentences = sentences[train_size:]\n",
    "test_y = y[train_size:]\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=100, padding='post', truncating='post')\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(5000, 16, input_length=100),\n",
    "#     tf.keras.layers.Bidirectional(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(9, activation='exponential'),\n",
    "#     tf.keras.layers.Dense(18, activation='relu'),\n",
    "\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "model.fit(\n",
    "    train_padded,\n",
    "    train_y,\n",
    "    epochs=15,\n",
    "    validation_split=0.1\n",
    ")\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=100, padding='post', truncating='post')\n",
    "model.evaluate(test_padded, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "988b8f7e",
   "metadata": {
    "cellId": "1tb0hz81axuia0mcl135q8s"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model.save('/home/jupyter/mnt/s3/main-data/models/model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "fd14421e",
   "metadata": {
    "cellId": "4798krracv50ld9nsq1o7od"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 100, 16)           80000     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_22  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 9)                 153       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 12)                120       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 3)                 39        \n",
      "=================================================================\n",
      "Total params: 80,312\n",
      "Trainable params: 80,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 0.9844 - accuracy: 0.5243 - val_loss: 0.8876 - val_accuracy: 0.5261\n",
      "Epoch 2/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.7158 - accuracy: 0.7170 - val_loss: 0.6033 - val_accuracy: 0.7708\n",
      "Epoch 3/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.5475 - accuracy: 0.7841 - val_loss: 0.5249 - val_accuracy: 0.7915\n",
      "Epoch 4/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.4779 - accuracy: 0.8054 - val_loss: 0.4945 - val_accuracy: 0.8005\n",
      "Epoch 5/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.4325 - accuracy: 0.8316 - val_loss: 0.4596 - val_accuracy: 0.8231\n",
      "Epoch 6/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3877 - accuracy: 0.8579 - val_loss: 0.4385 - val_accuracy: 0.8393\n",
      "Epoch 7/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3515 - accuracy: 0.8755 - val_loss: 0.4237 - val_accuracy: 0.8515\n",
      "Epoch 8/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.8828 - val_loss: 0.4165 - val_accuracy: 0.8677\n",
      "Epoch 9/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.3061 - accuracy: 0.8889 - val_loss: 0.4150 - val_accuracy: 0.8599\n",
      "Epoch 10/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2914 - accuracy: 0.8947 - val_loss: 0.4152 - val_accuracy: 0.8651\n",
      "Epoch 11/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2732 - accuracy: 0.9001 - val_loss: 0.4095 - val_accuracy: 0.8677\n",
      "Epoch 12/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2600 - accuracy: 0.9030 - val_loss: 0.4126 - val_accuracy: 0.8651\n",
      "Epoch 13/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2473 - accuracy: 0.9074 - val_loss: 0.4107 - val_accuracy: 0.8689\n",
      "Epoch 14/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2369 - accuracy: 0.9085 - val_loss: 0.4163 - val_accuracy: 0.8657\n",
      "Epoch 15/15\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 0.2286 - accuracy: 0.9105 - val_loss: 0.4416 - val_accuracy: 0.8657\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43065235018730164, 0.8659953474998474]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_size = int(len(sentences) * 0.8)\n",
    "train_sentences = sentences[:train_size]\n",
    "train_y = y[:train_size]\n",
    "test_sentences = sentences[train_size:]\n",
    "test_y = y[train_size:]\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=100, padding='post', truncating='post')\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(5000, 16, input_length=100),\n",
    "#     tf.keras.layers.Bidirectional(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(9, activation='relu'),\n",
    "    tf.keras.layers.Dense(12, activation='relu'),\n",
    "\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "model.fit(\n",
    "    train_padded,\n",
    "    train_y,\n",
    "    epochs=15,\n",
    "    validation_split=0.1\n",
    ")\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=100, padding='post', truncating='post')\n",
    "model.evaluate(test_padded, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "1464743c",
   "metadata": {
    "cellId": "pmqxhayuntroqolo22ukje"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model.save('/home/jupyter/mnt/s3/main-data/models/model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cdcb22",
   "metadata": {
    "cellId": "omtinnixj9ye946xjxfqm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "f4373bfd-62d6-49eb-b51b-5ab4b9601c2a",
  "notebookPath": "hse-hackaton/Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
